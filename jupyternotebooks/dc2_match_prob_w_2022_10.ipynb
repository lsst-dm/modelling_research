{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import lsst.daf.butler as dafButler\n",
    "import lsst.geom as geom\n",
    "\n",
    "import modelling_research.meas_model as mrMeas\n",
    "from modelling_research.plot_matches import plot_matches\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setup for plotting\n",
    "plot = True\n",
    "if plot:\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    %matplotlib inline\n",
    "    sns.set_style('darkgrid')\n",
    "    mpl.rcParams['figure.dpi'] = 160\n",
    "    mpl.rcParams['image.origin'] = 'lower'\n",
    "    sns.set(rc={'axes.facecolor': '0.85', 'figure.facecolor': 'w'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load data and setup column lists\n",
    "weekly = 'w_2022_10'\n",
    "ticket = 'DM-33905'\n",
    "\n",
    "butler = dafButler.Butler(\n",
    "    '/repo/dc2',\n",
    "    collections=[\n",
    "        '2.2i/truth_summary',\n",
    "        f'2.2i/runs/test-med-1/{weekly}/{ticket}',\n",
    "    ]\n",
    ")\n",
    "\n",
    "tracts = (3828, 3829)\n",
    "band_ref = 'r'\n",
    "mag_tot_min, mag_tot_max = 0., 27.\n",
    "mag_zeropoint = 31.4\n",
    "name_bands = 'ugrizy'\n",
    "bands = tuple(x for x in name_bands)\n",
    "model_target = 'cModel'\n",
    "\n",
    "use_fluxes = True\n",
    "\n",
    "columns_fluxes_target = [f'{band}_{model_target}Flux' for band in bands]\n",
    "columns_data_target = ['x', 'y']\n",
    "if use_fluxes:\n",
    "    columns_data_target.extend(columns_fluxes_target)\n",
    "columns_errors_target = [f'{col}Err' for col in columns_data_target]\n",
    "columns_all_target = ['objectId', 'merge_peak_sky', 'detect_isPrimary', 'patch']\n",
    "columns_all_target.extend(columns_data_target)\n",
    "columns_all_target.extend(columns_errors_target)\n",
    "if not use_fluxes:\n",
    "    columns_all_target.extend(columns_all_target)\n",
    "\n",
    "columns_fluxes_ref = [f'flux_{band}' for band in bands]\n",
    "columns_data_ref = ['ra', 'dec']\n",
    "if use_fluxes:\n",
    "    columns_data_ref += columns_fluxes_ref\n",
    "columns_all_ref = ['id']\n",
    "columns_all_ref.extend(columns_data_ref)\n",
    "columns_all_ref.extend(columns_fluxes_ref)\n",
    "\n",
    "if plot:\n",
    "    columns_all_ref.append('is_pointsource')\n",
    "    columns_all_target.append('refExtendedness')\n",
    "    columns_all_target.extend([f'{band}_psfFlux{suffix}' for band in bands for suffix in ('', 'Err')])\n",
    "\n",
    "# We only measure chi^2 from x, y because we don't have ra, dec errors (yet)\n",
    "columns_data_ref[:2] = 'x', 'y'\n",
    "\n",
    "match_dist_max = geom.Angle(0.5, geom.arcseconds)\n",
    "# Two coordinates and one band\n",
    "n_finite_min = 2 + use_fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"No value in data ID ({}) for required dimension 'skymap'.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/software/lsstsw/stack_20220215/stack/miniconda3-py38_4.9.2-2.0.0/Linux64/daf_butler/g5d83a09a10+1837f4e714/python/lsst/daf/butler/core/dimensions/_coordinate.py:248\u001b[0m, in \u001b[0;36mDataCoordinate.standardize\u001b[0;34m(mapping, graph, universe, defaults, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequired\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/software/lsstsw/stack_20220215/stack/miniconda3-py38_4.9.2-2.0.0/Linux64/daf_butler/g5d83a09a10+1837f4e714/python/lsst/daf/butler/core/dimensions/_coordinate.py:248\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mrequired\u001b[38;5;241m.\u001b[39mnames)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'skymap'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     xy_true \u001b[38;5;241m=\u001b[39m wcs\u001b[38;5;241m.\u001b[39mskyToPixel(radec_true)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([xy[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m xy \u001b[38;5;129;01min\u001b[39;00m xy_true]), np\u001b[38;5;241m.\u001b[39marray([xy[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m xy \u001b[38;5;129;01min\u001b[39;00m xy_true])\n\u001b[0;32m----> 7\u001b[0m skymap \u001b[38;5;241m=\u001b[39m \u001b[43mbutler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mskyMap\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m cats_in, cats_out \u001b[38;5;241m=\u001b[39m {}, {}\n\u001b[1;32m     11\u001b[0m columns_match_ref \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch_row\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch_candidate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch_chisq\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch_n_chisq_finite\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/software/lsstsw/stack_20220215/stack/miniconda3-py38_4.9.2-2.0.0/Linux64/daf_butler/g5d83a09a10+1837f4e714/python/lsst/daf/butler/_butler.py:1320\u001b[0m, in \u001b[0;36mButler.get\u001b[0;34m(self, datasetRefOrType, dataId, parameters, collections, **kwargs)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;124;03m\"\"\"Retrieve a stored dataset.\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m \n\u001b[1;32m   1273\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;124;03m``exposure`` is a temporal dimension.\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1319\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mButler get: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, dataId=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, parameters=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, datasetRefOrType, dataId, parameters)\n\u001b[0;32m-> 1320\u001b[0m ref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_findDatasetRef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasetRefOrType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataId\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetDirect(ref, parameters\u001b[38;5;241m=\u001b[39mparameters)\n",
      "File \u001b[0;32m/software/lsstsw/stack_20220215/stack/miniconda3-py38_4.9.2-2.0.0/Linux64/daf_butler/g5d83a09a10+1837f4e714/python/lsst/daf/butler/_butler.py:1024\u001b[0m, in \u001b[0;36mButler._findDatasetRef\u001b[0;34m(self, datasetRefOrType, dataId, collections, allowUnresolved, **kwargs)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         timespan \u001b[38;5;241m=\u001b[39m dataId\u001b[38;5;241m.\u001b[39mtimespan\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;66;03m# Standardize the data ID to just the dimensions of the dataset\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;66;03m# type instead of letting registry.findDataset do it, so we get the\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;66;03m# result even if no dataset is found.\u001b[39;00m\n\u001b[0;32m-> 1024\u001b[0m     dataId \u001b[38;5;241m=\u001b[39m \u001b[43mDataCoordinate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstandardize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataId\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasetType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefaults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataId\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# Always lookup the DatasetRef, even if one is given, to ensure it is\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;66;03m# present in the current collection.\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m ref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregistry\u001b[38;5;241m.\u001b[39mfindDataset(datasetType, dataId, collections\u001b[38;5;241m=\u001b[39mcollections, timespan\u001b[38;5;241m=\u001b[39mtimespan)\n",
      "File \u001b[0;32m/software/lsstsw/stack_20220215/stack/miniconda3-py38_4.9.2-2.0.0/Linux64/daf_butler/g5d83a09a10+1837f4e714/python/lsst/daf/butler/core/dimensions/_coordinate.py:250\u001b[0m, in \u001b[0;36mDataCoordinate.standardize\u001b[0;34m(mapping, graph, universe, defaults, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(d[name] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mrequired\u001b[38;5;241m.\u001b[39mnames)\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo value in data ID (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) for required dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# Some backends cannot handle numpy.int64 type which is a subclass of\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# numbers.Integral; convert that to int.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28mint\u001b[39m(val) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, numbers\u001b[38;5;241m.\u001b[39mIntegral) \u001b[38;5;28;01melse\u001b[39;00m val \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m values  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    255\u001b[0m )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"No value in data ID ({}) for required dimension 'skymap'.\""
     ]
    }
   ],
   "source": [
    "# Load matched catalogs\n",
    "def get_xy(ras, decs, wcs):\n",
    "    radec_true = [geom.SpherePoint(ra, dec, geom.degrees) for ra, dec in zip(ras, decs)]\n",
    "    xy_true = wcs.skyToPixel(radec_true)\n",
    "    return np.array([xy[0] for xy in xy_true]), np.array([xy[1] for xy in xy_true])\n",
    "\n",
    "skymap = butler.get('skyMap')\n",
    "\n",
    "cats_in, cats_out = {}, {}\n",
    "\n",
    "columns_match_ref = ('match_row', 'match_candidate', 'match_chisq', 'match_n_chisq_finite')\n",
    "\n",
    "for tract in tracts:\n",
    "    cat_target, cat_ref, cat_match_ref = (\n",
    "        butler.get(\n",
    "            dataset,\n",
    "            tract=tract,\n",
    "            parameters={\"columns\": columns},\n",
    "        )\n",
    "        for dataset, columns in (\n",
    "            ('objectTable_tract', columns_all_target),\n",
    "            ('truth_summary', columns_all_ref),\n",
    "            ('match_ref_truth_summary_objectTable_tract', columns_match_ref),\n",
    "        )\n",
    "    )\n",
    "    x, y = get_xy(cat_ref['ra'], cat_ref['dec'], wcs=skymap[tract].getWcs())\n",
    "    cat_ref['x'], cat_ref['y'] = x, y\n",
    "    cats_in[tract] = (cat_ref, cat_target)\n",
    "    # We don't need match_target for now\n",
    "    cats_out[tract] = (cat_match_ref, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Concat tracts\n",
    "\n",
    "# Keep track of row ranges for each ref cat\n",
    "cat_ref_all = [cat for cat, _ in cats_out.values()]\n",
    "n_rows_refs = [len(cat) for cat in cat_ref_all]\n",
    "cat_ref_all = pd.concat(cat_ref_all, axis=0, ignore_index=True)\n",
    "\n",
    "# ... and row ranges for target cats\n",
    "cat_target_all = [cat for _, cat in cats_in.values()]\n",
    "n_rows_targets = [len(cat) for cat in cat_target_all]\n",
    "cat_target_all = pd.concat(cat_target_all, axis=0, ignore_index=True)\n",
    "\n",
    "# Increment indices to point to the right index in the merged table\n",
    "for n_rows_ref, n_rows_target in zip(n_rows_refs[:-1], n_rows_targets[:-1]):\n",
    "    cat_ref_all.loc[n_rows_ref:, 'match_row'] += n_rows_target * (cat_ref_all.iloc[n_rows_ref:]['match_row'] >= 0)\n",
    "\n",
    "idx_match_count = np.bincount(cat_ref_all['match_row'][cat_ref_all['match_row'] >= 0])\n",
    "\n",
    "# Merge and concat target cat (containing row indices) with full inputs\n",
    "cat_ref_in = pd.concat([cat for cat, _ in cats_in.values()], axis=0, ignore_index=True)\n",
    "cat_ref_all = pd.concat([cat_ref_all, cat_ref_in], axis=1)\n",
    "\n",
    "select_target=(~cat_target_all['merge_peak_sky'] & cat_target_all['detect_isPrimary']).values,\n",
    "\n",
    "n_matched = np.sum(cat_ref_all['match_row'] >= 0)\n",
    "n_matched_uniq = len(set(cat_ref_all['match_row']))\n",
    "\n",
    "# There's always a min_int sentinel, unless everything was matched (that would be strange!)\n",
    "if n_matched_uniq != n_matched + 1:\n",
    "    raise RuntimeError(f'n_matched={n_matched} != n_matched_uniq={n_matched_uniq}')\n",
    "print(f'Matched {n_matched}/{len(cat_ref_all)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot basics\n",
    "import matplotlib.pyplot as plt\n",
    "chisq = cat_ref_all['match_chisq']\n",
    "n_match = cat_ref_all['match_n_chisq_finite']\n",
    "mag_ref = -2.5*np.log10(cat_ref_all[f'flux_{band_ref}']) + mag_zeropoint\n",
    "\n",
    "_ = plt.hist(np.clip(np.log10((chisq[chisq > 0]/n_match[chisq > 0])), -1.5, 2.5), bins=100)\n",
    "\n",
    "mag_plot_min, mag_plot_max = 15, mag_tot_max + 0.5\n",
    "n_bins = int(np.round(10*(mag_plot_max - mag_plot_min)))\n",
    "bins = np.linspace(mag_plot_min, mag_plot_max, num=n_bins + 1)\n",
    "n_obj = np.zeros(n_bins, dtype=int)\n",
    "n_matched = np.zeros(n_bins, dtype=int)\n",
    "\n",
    "for idx in range(n_bins):\n",
    "    within = (mag_ref > bins[idx]) & (mag_ref < bins[idx+1])\n",
    "    n_obj[idx] = np.sum(within)\n",
    "    n_matched[idx] = np.sum(chisq[within] > 0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(bins[:-1], n_matched/n_obj)\n",
    "\n",
    "mag_psf_ref = -2.5*np.log10(cats_in[tract][1][f'{band_ref}_psfFlux'].values) + mag_zeropoint\n",
    "matched = np.zeros(len(cats_in[tract][1]), dtype=bool)\n",
    "matched[cats_out[tract][0]['match_row'].values[cats_out[tract][0]['match_row'] >= 0]] = True\n",
    "\n",
    "for idx in range(n_bins):\n",
    "    within = (mag_psf_ref > bins[idx]) & (mag_psf_ref < bins[idx+1]) & cats_in[tract][1]['detect_isPrimary'] & ~cats_in[tract][1]['merge_peak_sky']\n",
    "    n_obj[idx] = np.sum(within)\n",
    "    n_matched[idx] = np.sum(matched[within])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(bins[:-1], n_matched/n_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot matches nicely\n",
    "models = {\n",
    "    desc: mrMeas.Model(\n",
    "        desc, field, n_comps,\n",
    "        column_flux='Flux',\n",
    "        column_separator='',\n",
    "        column_band_prefixed=True,\n",
    "        prefix_centroid_default='',\n",
    "    )\n",
    "    for desc, field, n_comps in [\n",
    "        ('PSF', 'psf', 1),\n",
    "        ('Stack CModel', 'cModel', 2),\n",
    "    ]\n",
    "}\n",
    "\n",
    "select_target = ~cat_target_all['merge_peak_sky'].values & cat_target_all['detect_isPrimary'].values\n",
    "select_ref = cat_ref_all['match_candidate']\n",
    "\n",
    "kwargs = {\n",
    "    'scatterleft': True,\n",
    "    'scatterright': True,\n",
    "    'fluxes_true': {band: cat_ref_all.loc[select_ref, f'flux_{band}'].values for band in bands},\n",
    "    'centroids_ref': {'x': 'x', 'y': 'y'},\n",
    "    'limx': (mag_plot_min, mag_tot_max - 1),\n",
    "    'limits_y_chi': (-10., 10.),\n",
    "    'limits_y_dist': (0., 2.5),\n",
    "    'match_dist_asec': match_dist_max.asArcseconds(),\n",
    "    'mag_bin_complete': 0.125,\n",
    "    'mag_zeropoint_ref': mag_zeropoint,\n",
    "    'mag_max': mag_plot_max,\n",
    "    'models': models,\n",
    "    'models_purity': ('PSF', 'Stack CModel'),\n",
    "    'models_diff': ('Stack CModel',),\n",
    "    'models_dist': ('Stack CModel',),\n",
    "    'select_target': select_target,\n",
    "    'title': f'DC2 {\",\".join(str(tract) for tract in tracts) } {model_target}',\n",
    "    'compare_mags_psf_lim': (-2.45, 0.05),\n",
    "    'kwargs_get_mag': {'zeropoint': mag_zeropoint},\n",
    "}\n",
    "\n",
    "lim_y = {\n",
    "    \"resolved\": (-0.6, 0.4),\n",
    "    \"unresolved\": (-0.1, 0.05),\n",
    "}\n",
    "\n",
    "_ = plot_matches(\n",
    "    cat_ref_all[select_ref],\n",
    "    cat_target_all,\n",
    "    resolved=True,\n",
    "    plot_chi=True,\n",
    "    limits_y_diff=lim_y['resolved'],\n",
    "    limits_y_color_diff=lim_y['resolved'],\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot probable point sources\n",
    "_ = plot_matches(\n",
    "    cat_ref_all[select_ref],\n",
    "    cat_target_all,\n",
    "    resolved=False,\n",
    "    plot_chi=True,\n",
    "    limits_y_diff=lim_y['unresolved'],\n",
    "    limits_y_color_diff=lim_y['unresolved'],\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
