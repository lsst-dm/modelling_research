import argparse
import logging
import numpy as np
import sys

import lsst.afw.table as afwTable
from lsst.daf.persistence import Butler
from lsst.geom import SpherePoint, degrees
from multiprofit_task import MultiProFitTask


def getPatch(ra, dec, butler):
    """Get the patch that contains a given sky coordinate.

    Parameters
    ----------
    ra : `float`
        Right ascenscion in degrees.
    dec : `float`
        Declination in degrees.
    butler : `lsst.daf.persistence.Butler`
        A Generation 2 butler.

    Returns
    -------
    patch : `tuple` [`int`, `int`]
        The patch IDs containing the coordinates.
    """
    skymap = butler.get("deepCoadd_skyMap", dataId={"tract": tract})
    spherePoint = SpherePoint(ra, dec, degrees)
    tract = skymap.findTract(spherePoint).getId()
    return skymap[tract].findPatch(spherePoint)


def multiProFit(butler, tract, patchname, filters=None, exposureType=None, catalog=None,
                idx_begin=0, idx_end=np.Inf, printTrace=False, **kwargs):
    """Run the MultiProFit task on a range of sources in a region.

    Parameters
    ----------
    butler : `lsst.daf.persistence.Butler`
        A Generation 2 butler.
    tract : `int`
        A tract number.
    patchname : `str`
        The name of the patch in the tract to process.
    filters : iterable of `str`
        Names of bandpass filters for filter-dependent fields. Default ["HSC-I", "HSC-R", "HSC-G"].
    exposureType : `str`
        The type of exposure to retrieve from the butler. Default "deepCoadd_calexp".
    catalog : `lsst.afw.table.SourceCatalog`
        A catalog containing deblended sources with footprints. Default butler.get("deepCoadd_meas", dataId).
    idx_begin : `int`
        The first index (row number) of the catalog to process.
    idx_end : `int`
        The last index (row number) of the catalog to process.
    printTrace : `bool`
        Whether to print the traceback in case of an error.
    **kwargs
        Additional keyword arguments to pass to MultiProFitTask.run.

    Returns
    -------
    catalog : `lsst.afw.table.SimpleCatalog`
        A new catalog containing all of the fields from `sources` and those generated by MultiProFit.
    results : `dict`
        A results structure as returned by mpfFit.fit_galaxy_exposures() for the first successfully fit
        source.

    """
    if filters is None:
        filters = ["HSC-I", "HSC-R", "HSC-G"]
    if exposureType is None:
        exposureType = "deepCoadd_calexp"
    dataId = {"tract": tract, "patch": patchname, "filter": filters[0]}
    measCat = butler.get("deepCoadd_meas", dataId) if catalog is None else catalog
    #frame = 60
    #wcs = skymap[tract].getWcs()
    #point = wcs.skyToPixel(spherePoint)
    #sampleBBox = Box2I(Point2I(point[0] - frame, point[1] - frame), Extent2I(2 * frame, 2 * frame))
    coadds = {band: butler.get(exposureType, dataId, filter=band) for band in filters}
    config = MultiProFitTask.ConfigClass(**kwargs)
    task = MultiProFitTask(config=config)
    catalog, results = task.fit(coadds, measCat, idx_begin=idx_begin, idx_end=idx_end, printTrace=printTrace)
    return catalog, results


def main():
    parser = argparse.ArgumentParser(description='MultiProFit Butler Task running test')
    flags = {
        'repo': dict(type=str, nargs='?', default="/datasets/hsc/repo/rerun/RC/w_2019_26/DM-19560/",
                     help="Path to Butler repository to read from"),
        'inputFilename': dict(type=str, nargs='?', default=None, help="Output catalog filename"),
        'outputFilename': dict(type=str, nargs='?', default=None, help="Input catalog filename"),
        'radec': dict(type=float, nargs=2, default=None, help="RA/dec coordinate of source"),
        'patchName': dict(type=str, nargs='?', default="4,4", help="Butler patch string"),
        'tract': dict(type=int, nargs='?', default=9813, help="Butler tract ID"),
        'filters': dict(type=str, nargs='*', default=['HSC-I'], help="List of bandpass filters"),
        'idx_begin': dict(type=int, nargs='?', default=0, help="Initial row index to fit"),
        'idx_end': dict(type=int, nargs='?', default=np.Inf, help="Final row index to fit"),
        'printTrace': dict(type=bool, nargs='?', default=False, help="Print traceback for errors",
                           kwarg=True),
        'loglevel': {'type': int, 'nargs': '?', 'default': 21, 'help': 'logging.Logger default level'},
        'computeMeasModelfitLikelihood': dict(type=bool, nargs='?', default=False, kwarg=True,
                                              help="Set config computeMeasModelfitLikelihood flag", ),
        'fitCModelExp': dict(type=bool, nargs='?', default=False, kwarg=True,
                             help="Set config fitCModelExp flag"),
        'fitSersicFromCModel': dict(type=bool, nargs='?', default=False, kwarg=True,
                                    help="Set config fitSersicFromCModel flag"),
    }
    kwargs = {}
    for key, value in flags.items():
        if 'help' in value:
            value['help'] = f"{value['help']} (default: {str(value['default'])})"
        if 'kwarg' in value:
            kwargs[key] = None
            del value['kwarg']
        parser.add_argument('--' + key, **value)
    args = parser.parse_args()
    logging.basicConfig(stream=sys.stdout, level=args.loglevel)
    butler = Butler(args.repo)
    catalog = afwTable.SimpleCatalog.readFits(args.inputFilename) if args.inputFilename is not None else None
    if args.patchName is not None:
        patchname = args.patchName
    else:
        ra, dec = args.radec
        patch = getPatch(ra, dec, butler)
        patchname = ','.join([str(x) for x in patch.getIndex()])
    argsvars = vars(args)
    kwargs = {key: argsvars[key] for key in kwargs}
    catalog, results = multiProFit(
        butler, args.tract, patchname=patchname, catalog=catalog, filters=args.filters,
        idx_begin=args.idx_begin, idx_end=args.idx_end, **kwargs)
    if args.outputFilename is not None:
        catalog.writeFits(args.outputFilename)


if __name__ == '__main__':
    main()
